{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing, Yay!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#!pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>5.75606766236475E+017</td>\n",
       "      <td>5.75606766236475E+017</td>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>5.72333822886326E+017</td>\n",
       "      <td>5.72333822886326E+017</td>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>5.72326950057845E+017</td>\n",
       "      <td>5.72326950057845E+017</td>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>5.74799612642357E+017</td>\n",
       "      <td>5.74799612642357E+017</td>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>5.68826121153684E+017</td>\n",
       "      <td>5.68826121153684E+017</td>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index                     id  \\\n",
       "0      5.74948705591165E+017  5.74948705591165E+017   \n",
       "1      5.71917888690393E+017  5.71917888690393E+017   \n",
       "2      3.90255841338601E+017  3.90255841338601E+017   \n",
       "3      5.68208850655916E+017  5.68208850655916E+017   \n",
       "4      5.75596338802373E+017  5.75596338802373E+017   \n",
       "...                      ...                    ...   \n",
       "16846  5.75606766236475E+017  5.75606766236475E+017   \n",
       "16847  5.72333822886326E+017  5.72333822886326E+017   \n",
       "16848  5.72326950057845E+017  5.72326950057845E+017   \n",
       "16849  5.74799612642357E+017  5.74799612642357E+017   \n",
       "16850  5.68826121153684E+017  5.68826121153684E+017   \n",
       "\n",
       "                                                    Text Annotation  oh_label  \n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0  \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       none       0.0  \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0  \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0  \n",
       "4                                 #mkr No No No No No No       none       0.0  \n",
       "...                                                  ...        ...       ...  \n",
       "16846  Feeling so sorry for the girls, they should be...       none       0.0  \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       none       0.0  \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       none       0.0  \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       none       0.0  \n",
       "16850  And before you protest that you're *not* mad, ...       none       0.0  \n",
       "\n",
       "[16851 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_parsed_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@halalflaws @biebervalue @greenlinerzjm I read them in context.No change in meaning. The history of Islamic slavery. https://t.co/xWJzpSodGj \n",
      "\n",
      "@ShreyaBafna3 Now you idiots claim that people who tried to stop him from becoming a terrorist made him a terrorist. Islamically brain dead. \n",
      "\n",
      "RT @Mooseoftorment Call me sexist, but when I go to an auto place, I'd rather talk to a guy \n",
      "\n",
      "@g0ssipsquirrelx Wrong, ISIS follows the example of Mohammed and the Quran exactly. \n",
      "\n",
      "#mkr No No No No No No \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['Text'].iloc[0], \"\\n\")\n",
    "print(df['Text'].iloc[1], \"\\n\")\n",
    "print(df['Text'].iloc[2], \"\\n\")\n",
    "print(df['Text'].iloc[3], \"\\n\")\n",
    "print(df['Text'].iloc[4], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not all Muslims are violent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be or not to be</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're so stupid!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What happens if machines take over the world?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women have as much a right to education as men.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is not a hate speech.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I don't hate people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kill yourself nigger.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My Grandma's a Muslim. Such a kind woman.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Black people are literally a subspecies. You c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It's how the world has moved on from Russia an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Chinese are only good at making fakes and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I don't trust Asians, they should just stay wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I hate that women still have such limited opti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I hate when people don't text in full, like wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I hate egusi and amala. the two should not go ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I hate being sick. Combine that with burnout, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I really hate the taste of cilantro; it ruins ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>She doesn't hate the idea of moving to a new c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hey hate losing their keys because it always m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I hate how my favorite show got canceled; it w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>He hates the feeling of being unprepared for a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>She hates the thought of missing out on the co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I hate when my phone battery dies in the middl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>She hates getting caught in traffic, especiall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>He hates that the recipe calls for so many ing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>They hate how the new software update changed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I hate the feeling of missing out on a good bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>She hates when people interrupt her while she’...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>He hates the cold weather, so he prefers to st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>They hate how their favorite restaurant has su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I hate the sound of nails on a chalkboard; it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>She hates having to do the dishes after a big ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Why do we even let these clueless fools make d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>It’s frustrating to deal with these brainless ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  oh_label\n",
       "0                        Not all Muslims are violent.         0\n",
       "1                                  To be or not to be         0\n",
       "2                                   You're so stupid!         0\n",
       "3       What happens if machines take over the world?         0\n",
       "4     Women have as much a right to education as men.         0\n",
       "5                          This is not a hate speech.         0\n",
       "6                                 I don't hate people         0\n",
       "7                               Kill yourself nigger.         1\n",
       "8           My Grandma's a Muslim. Such a kind woman.         0\n",
       "9   Black people are literally a subspecies. You c...         1\n",
       "10  It's how the world has moved on from Russia an...         0\n",
       "11  The Chinese are only good at making fakes and ...         1\n",
       "12  I don't trust Asians, they should just stay wh...         1\n",
       "13  I hate that women still have such limited opti...         0\n",
       "14  I hate when people don't text in full, like wh...         0\n",
       "15  I hate egusi and amala. the two should not go ...         0\n",
       "16  I hate being sick. Combine that with burnout, ...         0\n",
       "17  I really hate the taste of cilantro; it ruins ...         0\n",
       "18  She doesn't hate the idea of moving to a new c...         0\n",
       "19  hey hate losing their keys because it always m...         0\n",
       "20  I hate how my favorite show got canceled; it w...         0\n",
       "21  He hates the feeling of being unprepared for a...         0\n",
       "22  She hates the thought of missing out on the co...         0\n",
       "23  I hate when my phone battery dies in the middl...         0\n",
       "24  She hates getting caught in traffic, especiall...         0\n",
       "25  He hates that the recipe calls for so many ing...         0\n",
       "26  They hate how the new software update changed ...         0\n",
       "27  I hate the feeling of missing out on a good bo...         0\n",
       "28  She hates when people interrupt her while she’...         0\n",
       "29  He hates the cold weather, so he prefers to st...         0\n",
       "30  They hate how their favorite restaurant has su...         0\n",
       "31  I hate the sound of nails on a chalkboard; it ...         0\n",
       "32  She hates having to do the dishes after a big ...         0\n",
       "33  Why do we even let these clueless fools make d...         1\n",
       "34  It’s frustrating to deal with these brainless ...         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel('HateReviews.xlsx')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I hate how my favorite show got canceled; it w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He hates the feeling of being unprepared for a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She hates the thought of missing out on the co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I hate when my phone battery dies in the middl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She hates getting caught in traffic, especiall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He hates that the recipe calls for so many ing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16874</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They hate how the new software update changed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16875</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I hate the feeling of missing out on a good bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16876</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She hates when people interrupt her while she’...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16877</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He hates the cold weather, so he prefers to st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16878</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They hate how their favorite restaurant has su...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16879</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I hate the sound of nails on a chalkboard; it ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She hates having to do the dishes after a big ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why do we even let these clueless fools make d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It’s frustrating to deal with these brainless ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   id                                               Text  \\\n",
       "16868   NaN  NaN  I hate how my favorite show got canceled; it w...   \n",
       "16869   NaN  NaN  He hates the feeling of being unprepared for a...   \n",
       "16870   NaN  NaN  She hates the thought of missing out on the co...   \n",
       "16871   NaN  NaN  I hate when my phone battery dies in the middl...   \n",
       "16872   NaN  NaN  She hates getting caught in traffic, especiall...   \n",
       "16873   NaN  NaN  He hates that the recipe calls for so many ing...   \n",
       "16874   NaN  NaN  They hate how the new software update changed ...   \n",
       "16875   NaN  NaN  I hate the feeling of missing out on a good bo...   \n",
       "16876   NaN  NaN  She hates when people interrupt her while she’...   \n",
       "16877   NaN  NaN  He hates the cold weather, so he prefers to st...   \n",
       "16878   NaN  NaN  They hate how their favorite restaurant has su...   \n",
       "16879   NaN  NaN  I hate the sound of nails on a chalkboard; it ...   \n",
       "16880   NaN  NaN  She hates having to do the dishes after a big ...   \n",
       "16881   NaN  NaN  Why do we even let these clueless fools make d...   \n",
       "16882   NaN  NaN  It’s frustrating to deal with these brainless ...   \n",
       "\n",
       "      Annotation  oh_label  \n",
       "16868        NaN       0.0  \n",
       "16869        NaN       0.0  \n",
       "16870        NaN       0.0  \n",
       "16871        NaN       0.0  \n",
       "16872        NaN       0.0  \n",
       "16873        NaN       0.0  \n",
       "16874        NaN       0.0  \n",
       "16875        NaN       0.0  \n",
       "16876        NaN       0.0  \n",
       "16877        NaN       0.0  \n",
       "16878        NaN       0.0  \n",
       "16879        NaN       0.0  \n",
       "16880        NaN       0.0  \n",
       "16881        NaN       1.0  \n",
       "16882        NaN       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf = pd.concat([df, df2], axis = 0, ignore_index=True)\n",
    "ldf.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16878</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hate favorite restaurant long wait times weekends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16879</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hate sound nails chalkboard makes skin crawl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hates dishes big meal least favorite chore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>even let clueless fools make decisions theyre ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frustrating deal brainless individuals cant gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   id                                               Text  \\\n",
       "16878   NaN  NaN  hate favorite restaurant long wait times weekends   \n",
       "16879   NaN  NaN       hate sound nails chalkboard makes skin crawl   \n",
       "16880   NaN  NaN         hates dishes big meal least favorite chore   \n",
       "16881   NaN  NaN  even let clueless fools make decisions theyre ...   \n",
       "16882   NaN  NaN  frustrating deal brainless individuals cant gr...   \n",
       "\n",
       "      Annotation  oh_label  \n",
       "16878        NaN       0.0  \n",
       "16879        NaN       0.0  \n",
       "16880        NaN       0.0  \n",
       "16881        NaN       1.0  \n",
       "16882        NaN       0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining a function to clean the tweets' text\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text, flags = re.MULTILINE)\n",
    "    test = re.sub(r\"\\@w+|\\#\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    tweet_tokens = word_tokenize(text)\n",
    "    text = [word for word in text.split(\" \") if word not in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "ldf.Text = ldf[\"Text\"].apply(clean)\n",
    "ldf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizing(data):\n",
    "    tweet = [lemmatizer.lemmatize(w) for w in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf['Text'] = ldf['Text'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        halalflaws biebervalue greenlinerzjm read cont...\n",
       "1        shreyabafna3 idiots claim people tried stop be...\n",
       "2        rt mooseoftorment call sexist go auto place id...\n",
       "3        g0ssipsquirrelx wrong isis follows example moh...\n",
       "4                                                      mkr\n",
       "                               ...                        \n",
       "16878    hate favorite restaurant long wait times weekends\n",
       "16879         hate sound nails chalkboard makes skin crawl\n",
       "16880           hates dishes big meal least favorite chore\n",
       "16881    even let clueless fools make decisions theyre ...\n",
       "16882    frustrating deal brainless individuals cant gr...\n",
       "Name: Text, Length: 16883, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oh_label\n",
       "0.0    11531\n",
       "1.0     5352\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf['oh_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a Bigram language model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the vectoriser\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(1,2)).fit(ldf['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 128343 \n",
      "\n",
      "First 20 features: \n",
      "['000' '000 mkr' '00simmerforlife' '00simmerforlife im' '01151900'\n",
      " '01151900 soon' '02' '02 feb' '05' '05 sb' '06jank'\n",
      " '06jank patrickosgood' '0cclus' '0cclus think' '0rwellian'\n",
      " '0rwellian labor' '0xabad1dea' '0xabad1dea amazon' '0xabad1dea bm'\n",
      " '0xabad1dea certain']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "print(\"Number of features: {} \\n\".format(len(feature_names)))\n",
    "print(\"First 20 features: \\n{}\".format(feature_names[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Trigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the vectoriser\n",
    "\n",
    "vect2 = TfidfVectorizer(ngram_range=(1,3)).fit(ldf['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 239648 \n",
      "\n",
      "First 20 features: \n",
      "['000' '000 mkr' '00simmerforlife' '00simmerforlife im'\n",
      " '00simmerforlife im sexist' '01151900' '01151900 soon' '02' '02 feb'\n",
      " '02 feb 1100' '05' '05 sb' '05 sb getting' '06jank'\n",
      " '06jank patrickosgood' '06jank patrickosgood blah'\n",
      " '06jank patrickosgood erdogan' '06jank patrickosgood evidence'\n",
      " '06jank patrickosgood give' '06jank patrickosgood schools']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect2.get_feature_names_out()\n",
    "print(\"Number of features: {} \\n\".format(len(feature_names)))\n",
    "print(\"First 20 features: \\n{}\".format(feature_names[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Defining training data for the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ldf['Text']\n",
    "Y = ldf['oh_label']\n",
    "\n",
    "X = vect2.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16883x239648 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 407618 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vect2, open(\"hatemodel/services/vectoriser.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Guess I'll have to oversample, too. Fun.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling the existing data with ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X, Y) # Now X_resampled and y_resampled contain the oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_resampled,y_resampled, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17778,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4445,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4445x239648 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 132590 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building the Logistic Regression Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy is  87.78\n"
     ]
    }
   ],
   "source": [
    "#Building the Logistic Regression Model\n",
    "logreg = LogisticRegression(penalty = 'l2', C = 1.0) #enforcing data regularisation with the penalty argument set to L2\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg_predict = logreg.predict(x_test)\n",
    "logreg_acc = accuracy_score(logreg_predict, y_test)\n",
    "print(\"The model's accuracy is {: .2f}\".format(logreg_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2139  198]\n",
      " [ 344 1756]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.92      0.89      2337\n",
      "         1.0       0.90      0.84      0.87      2100\n",
      "\n",
      "    accuracy                           0.88      4437\n",
      "   macro avg       0.88      0.88      0.88      4437\n",
      "weighted avg       0.88      0.88      0.88      4437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, logreg_predict))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, logreg_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hyperparameter Tuning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.92\n",
      "\n",
      "Best parameters: {'C': 100, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[100, 10, 1.0, 0.1, 0.01], 'solver':['newton-cg', 'lbfgs', 'liblinear']}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv = 5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\\n\".format(grid.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 93.16%\n"
     ]
    }
   ],
   "source": [
    "logreg_acc2 = accuracy_score(y_pred, y_test)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93.16%'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedacc = \"{:.2f}%\".format(logreg_acc2*100)\n",
    "savedacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(savedacc, open(\"hatemodel/services/accuracy.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2207  149]\n",
      " [ 155 1934]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94      2356\n",
      "         1.0       0.93      0.93      0.93      2089\n",
      "\n",
      "    accuracy                           0.93      4445\n",
      "   macro avg       0.93      0.93      0.93      4445\n",
      "weighted avg       0.93      0.93      0.93      4445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hates'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = lemmatizing(clean(\"He hates you.\"))\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x239648 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = vect2.transform(input_data.split(\" \"))\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Exporting trained model into pickle file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Trained Model using Pickle\n",
    "pickle.dump(grid, open('hatemodel/services/savedmodel.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
